{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_ndvi = pd.read_csv(\"data/train/NDVI.csv\", encoding=\"windows-1251\").drop(columns=[\"index\"])\n",
    "df_nir = pd.read_csv(\"data/train/B8A.csv\", encoding=\"windows-1251\").drop(columns=[\"index\", \"culture\"]).add_suffix(\"_nir\")\n",
    "df_swir = pd.read_csv(\"data/train/B12.csv\", encoding=\"windows-1251\").drop(columns=[\"index\", \"culture\"]).add_suffix(\"_swir\")\n",
    "df_red = pd.read_csv(\"data/train/B04.csv\", encoding=\"windows-1251\").drop(columns=[\"index\", \"culture\"]).add_suffix(\"_red\")\n",
    "df_VegRedEdge = pd.read_csv(\"data/train/B05.csv\", encoding=\"windows-1251\").drop(columns=[\"index\", \"culture\"]).add_suffix(\"_vegRedEdge\")\n",
    "df_blue = pd.read_csv(\"data/train/B02.csv\", encoding=\"windows-1251\").drop(columns=[\"index\", \"culture\"]).add_suffix(\"_blue\")\n",
    "df_green = pd.read_csv(\"data/train/B03.csv\", encoding=\"windows-1251\").drop(columns=[\"index\", \"culture\"]).add_suffix(\"_green\")\n",
    "\n",
    "labels = df_ndvi[\"culture\"]\n",
    "df_ndvi.drop(columns=[\"culture\"], inplace=True)\n",
    "\n",
    "data = pd.concat([df_ndvi, df_nir, df_swir, df_red, df_VegRedEdge, df_blue, df_green], axis=1)\n",
    "data[\"121\"].isna().sum()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DataImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, impute_type: str = \"mean\", window_size: int = 5):\n",
    "        self.impute_type = impute_type\n",
    "        self.window_size = window_size + 1\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame, y=None) -> pd.DataFrame:\n",
    "        data: pd.DataFrame = X.copy()\n",
    "        if self.impute_type == \"mean\":\n",
    "            for column in data.columns:\n",
    "                data[column] = data[column].fillna(data[column].mean())\n",
    "            return data\n",
    "\n",
    "        if self.impute_type == \"rolling_mean\":\n",
    "            for column in data.columns:\n",
    "                data[column] = data[column].fillna(data[column].rolling(window=self.window_size, min_periods=1).mean())\n",
    "            return data\n",
    "\n",
    "        if self.impute_type == \"ffil\":\n",
    "            return data.ffill()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class VegetationIndexAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, ndwi: bool = True, arvi: bool = True, sawi: bool = True, gemi: bool = True, ndre: bool = True, gndwi: bool = True, evi: bool = True, msavi: bool = True) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.N_DAYS = 26\n",
    "        self.DAYS = ['121', '128', '135', '142', '149', '156', '163', '170', '177', '184', '191', '198', '205', \n",
    "                                '212', '219', '226', '233', '240', '247', '254', '261', '268', '275', '282', '289', '296']\n",
    "        \n",
    "        self.NDVI_START = 0\n",
    "        self.NIR_START = 26\n",
    "        self.SWIR_START = 52\n",
    "        self.RED_START = 78\n",
    "        self.VEG_REG_EDGE_START = 104\n",
    "        self.BLUE_START = 130\n",
    "        self.GREEN_START = 156\n",
    "\n",
    "        self.ndwi = ndwi\n",
    "        self.arvi = arvi\n",
    "        self.sawi = sawi\n",
    "        self.gemi = gemi\n",
    "        self.ndre = ndre\n",
    "        self.gndwi = gndwi\n",
    "        self.evi = evi\n",
    "        self.msavi = msavi\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame, y=None):\n",
    "        data = X.copy()\n",
    "\n",
    "        for day in self.DAYS:\n",
    "            nir = X[f\"{day}_nir\"]\n",
    "            red = X[f\"{day}_red\"]\n",
    "            blue = X[f\"{day}_blue\"]\n",
    "            swir = X[f\"{day}_swir\"]\n",
    "            veg_red_edge = X[f\"{day}_vegRedEdge\"]\n",
    "            green = X[f\"{day}_green\"]\n",
    "\n",
    "            discriminant = (2 * nir + 1) ** 2 - 8 * (nir * red)\n",
    "            sqrt_value = np.sqrt(np.maximum(discriminant, 0))\n",
    "            L = 1 - (2 * nir + 1 - sqrt_value) / 2\n",
    "\n",
    "            E = (2 * (nir ** 2 - red ** 2) + 1.5 * nir + 0.5 * red) / (nir + red + 0.5)\n",
    "            Rb = red - (red - blue)\n",
    "            msavi_expression = (2 * nir + 1) ** 2 - 8 * (nir - red)\n",
    "\n",
    "            if self.ndwi:\n",
    "                data[f\"{day}_ndwi\"] = (nir - swir) / (nir + swir)\n",
    "            if self.arvi:\n",
    "                data[f\"{day}_arvi\"] = (nir - Rb) / (nir + Rb)\n",
    "            if self.sawi:\n",
    "                data[f\"{day}_sawi\"] = (nir - red) / (nir + red - L) * (1 + L)\n",
    "            if self.gemi:\n",
    "                data[f\"{day}_gemi\"] = E * (1 - 0.25 * E) - ((red - 0.125) / (1 - red))\n",
    "            if self.ndre:\n",
    "                data[f\"{day}_ndre\"] = (nir - veg_red_edge) / (nir + veg_red_edge)\n",
    "            if self.gndwi:\n",
    "                data[f\"{day}_gndwi\"] = (nir - green) / (nir + green)\n",
    "            if self.evi:\n",
    "                data[f\"{day}_evi\"] = 2.5 * (nir - red) / (nir + 6 * red - 7.5 * blue + 1)\n",
    "            if self.msavi:\n",
    "                data[f\"{day}_msavi\"] = (2 * nir + 1 - np.sqrt(np.abs(msavi_expression)))\n",
    "\n",
    "\n",
    "            data = data.copy()\n",
    "            # data.drop(columns=[f\"{day}_nir\", f\"{day}_red\", f\"{day}_blue\", f\"{day}_swir\", f\"{day}_vegRedEdge\", f\"{day}_green\"], inplace=True)\n",
    "\n",
    "\n",
    "        return data\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pipe = make_pipeline(\n",
    "    DataImputer(impute_type=\"mean\"),\n",
    "    VegetationIndexAdder(),\n",
    "    HistGradientBoostingClassifier()\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=0)\n",
    "\n",
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"max_iter\": [100, 200, 300],\n",
    "    \"l2_regularization\": [0, 0.3, 0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(HistGradientBoostingClassifier(), param_grid=param_grid, cv=5, n_jobs=-1, scoring=\"f1\", verbose=4)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(grid_search.best_score_)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictions = pipe.predict(x_test)\n",
    "print(classification_report(y_test, predictions, digits=5))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "import dill\n",
    "import joblib\n",
    "\n",
    "info = {\n",
    "    \"model\": pipe,\n",
    "    \"column_suffixes\": {\n",
    "        \"ndvi\": \"\",\n",
    "        \"B8A\": \"_nir\",\n",
    "        \"B12\": \"_swir\",\n",
    "        \"B04\": \"_red\",\n",
    "        \"B05\": \"_vegRedEdge\",\n",
    "        \"B02\": \"_blue\",\n",
    "        \"B03\": \"_green\",\n",
    "    },\n",
    "    \"f1_score\": 0.989\n",
    "}\n",
    "\n",
    "with open(\"models/pickle_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(info, f)\n",
    "\n",
    "with open(\"models/dill_model.pkl\", \"wb\") as f:\n",
    "    dill.dump(info, f)\n",
    "\n",
    "joblib.dump(info, \"models/joblim_model.pkl\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(\"models/pickle_model.pkl\", \"rb\") as f:\n",
    "    unpickle_info = pickle.load(f)\n",
    "\n",
    "unpickle_model = unpickle_info[\"model\"]\n",
    "\n",
    "print(unpickle_info[\"column_suffixes\"])\n",
    "unpickle_model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "open_df_ndvi = pd.read_csv(\"data/test/test_public/NDVI.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"])\n",
    "open_df_nir = pd.read_csv(\"data/test/test_public/B8A.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_nir\")\n",
    "open_df_swir = pd.read_csv(\"data/test/test_public/B12.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_swir\")\n",
    "open_df_red = pd.read_csv(\"data/test/test_public/B04.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_red\")\n",
    "open_df_VegRedEdge = pd.read_csv(\"data/test/test_public/B05.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_vegRedEdge\")\n",
    "open_df_blue = pd.read_csv(\"data/test/test_public/B02.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_blue\")\n",
    "open_df_green = pd.read_csv(\"data/test/test_public/B03.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_green\")\n",
    "\n",
    "open_data = pd.concat([open_df_ndvi, open_df_nir, open_df_swir, open_df_red, open_df_VegRedEdge, open_df_blue, open_df_green], axis=1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import csv\n",
    "predictions: list[str] = unpickle_model.predict(open_data).tolist()\n",
    "\n",
    "with open(\"answers/classification_openset.csv\", mode=\"w\", newline=\"\", encoding=\"windows-1251\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    writer.writerow([\"culture\"])\n",
    "    for item in predictions:\n",
    "        writer.writerow([item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T05:00:55.931322Z",
     "start_time": "2024-10-05T05:00:55.713521Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "predictions: list[str] = unpickle_model.predict(open_data).tolist()\n",
    "\n",
    "with open(\"answers/classification_openset.csv\", mode=\"w\", newline=\"\", encoding=\"windows-1251\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    writer.writerow([\"culture\"])\n",
    "    for item in predictions:\n",
    "        writer.writerow([item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T05:03:21.697390Z",
     "start_time": "2024-10-05T05:03:21.639016Z"
    }
   },
   "outputs": [],
   "source": [
    "close_df_ndvi = pd.read_csv(\"data/test/test_closed/NDVI.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"])\n",
    "close_df_nir = pd.read_csv(\"data/test/test_closed/B8A.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_nir\")\n",
    "close_df_swir = pd.read_csv(\"data/test/test_closed/B12.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_swir\")\n",
    "close_df_red = pd.read_csv(\"data/test/test_closed/B04.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_red\")\n",
    "close_df_VegRedEdge = pd.read_csv(\"data/test/test_closed/B05.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_vegRedEdge\")\n",
    "close_df_blue = pd.read_csv(\"data/test/test_closed/B02.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_blue\")\n",
    "close_df_green = pd.read_csv(\"data/test/test_closed/B03.csv\", sep=\";\", encoding=\"windows-1251\").drop(columns=[\"index\"]).add_suffix(\"_green\")\n",
    "\n",
    "close_data = pd.concat([close_df_ndvi, close_df_nir, close_df_swir, close_df_red, close_df_VegRedEdge, close_df_blue, close_df_green], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T05:05:22.270912Z",
     "start_time": "2024-10-05T05:05:22.054784Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions: list[str] = unpickle_model.predict(close_data).tolist()\n",
    "\n",
    "with open(\"answers/classification_closedset.csv\", mode=\"w\", newline=\"\", encoding=\"windows-1251\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    writer.writerow([\"culture\"])\n",
    "    for item in predictions:\n",
    "        writer.writerow([item])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
